<style>
    h1 {
        color: #2c3e50;
    }
    h2 {
        color: #34495e;
    }
    p {
        font-family: Arial, sans-serif;
        line-height: 1.6;
        margin: 10px 0;
    }
    ul {
        margin: 10px 0 20px 20px;
    }
    table {
      width: 100%;
      border-collapse: separate;
      border-spacing: 5px 10px; /* Adds space between rows and columns */
      margin-bottom: 20px;
      background-color: #fff;
   }
   .download-link {
        margin: 20px 0;
        padding: 10px 15px;
        background-color: #3498db;
        color: white;
        font-size: 16px;
        text-align: center;
        text-decoration: none;
        display: inline-block;
        border-radius: 5px;
    }
    .download-link:hover {
        background-color: #2c80b4;
    }
</style>
  <h1>üìö Study Case: Air Quality and Pollution Assessment</h1>

  <div>
    <a href="https://drive.google.com/uc?export=download&id=120A66ljzKvK8wO-2uRVMY7DZi0qIvbyD" class="download-link" target="_blank">‚¨áÔ∏è Download Dataset</a>
</div>

  <h2>1. Introduction</h2>
  
  <p>The quality of air we breathe plays a crucial role in human health and environmental sustainability. 
    In this study case, we delve into the "Air Quality and Pollution Assessment" dataset, which provides 
    comprehensive information on pollution levels and air quality indicators. This dataset is particularly 
    suited for multiclass classification, making it an ideal candidate for testing our machine learning 
    pipeline and user interface in a Shiny R application.</p>
  
    <p><strong>The Objective:</strong> of this study case is to test the "Air Quality and Pollution Assessment" dataset in a 
        Shiny R application by performing the following steps:
    </p>
    <ul>
        <li>Preprocess the dataset to handle missing values and clean the data.</li>
        <li>Select an appropriate target variable for multiclass classification.</li>
        <li>Split the dataset into training and testing subsets.</li>
        <li>Train a classification model using SVM and Random Forest.</li>
    </ul>      
  
  <h2>2. Dataset Description</h2>
  <p><strong>Summary:</strong> The dataset includes the following features:</p>
  <ul>
    <li><code>Temperature (¬∞C)</code>: Average temperature of the region.</li>
    <li><code>Humidity (%)</code>: Relative humidity recorded in the region.</li>
    <li><code>PM2.5 Concentration (¬µg/m¬≥)</code>: Fine particulate matter levels.</li>
    <li><code>PM10 Concentration (¬µg/m¬≥)</code>: Coarse particulate matter levels.</li>
    <li><code>NO2 Concentration (ppb)</code>: Nitrogen dioxide levels.</li>
    <li><code>SO2 Concentration (ppb)</code>: Sulfur dioxide levels.</li>
    <li><code>CO Concentration (ppm)</code>: Carbon monoxide levels.</li>
    <li><code>Proximity to Industrial Areas (km)</code>: Distance to the nearest industrial zone.</li>
    <li><code>Population Density (people/km¬≤)</code>: Number of people per square kilometer in the region. </li>
  </ul>
  
  <p><strong>Target Variable: Air Quality Levels</strong>
  <ul>
    <li><code>Good</code>: Clean air with low pollution levels.</li>
    <li><code>Moderate</code>: Acceptable air quality but with some pollutants present.</li>
    <li><code>Poor</code>: Noticeable pollution that may cause health issues for sensitive groups.</li>
    <li><code>Hazardous</code>: Highly polluted air posing serious health risks to the population.</li>
  </ul>
  
  <p><strong>Details:</strong> Based on the results obtained from our Shiny R interface, we successfully demonstrated the following:
    </p>

  <table>
    <thead>
        <tr>
            <th>Column</th>
            <th>Class</th>
            <th>Missing</th>
            <th>Min</th>
            <th>Median</th>
            <th>Max</th>
            <th>Mean</th>
            <th>SD</th>
            <th>Variance</th>
            <th>Unique_Values</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Temperature</td>
            <td>Numerical</td>
            <td>0</td>
            <td>13.4</td>
            <td>29</td>
            <td>58.6</td>
            <td>30.029</td>
            <td>6.721</td>
            <td>45.167</td>
            <td>-</td>
        </tr>
        <tr>
            <td>Humidity</td>
            <td>Numerical</td>
            <td>0</td>
            <td>36</td>
            <td>69.8</td>
            <td>128.1</td>
            <td>70.056</td>
            <td>15.864</td>
            <td>251.653</td>
            <td>-</td>
        </tr>
        <tr>
            <td>PM2.5</td>
            <td>Numerical</td>
            <td>0</td>
            <td>0</td>
            <td>12</td>
            <td>295</td>
            <td>20.142</td>
            <td>24.555</td>
            <td>602.926</td>
            <td>-</td>
        </tr>
        <tr>
            <td>PM10</td>
            <td>Numerical</td>
            <td>0</td>
            <td>-0.2</td>
            <td>21.7</td>
            <td>315.8</td>
            <td>30.218</td>
            <td>27.349</td>
            <td>747.979</td>
            <td>-</td>
        </tr>
        <tr>
            <td>NO2</td>
            <td>Numerical</td>
            <td>0</td>
            <td>7.4</td>
            <td>25.3</td>
            <td>64.9</td>
            <td>26.412</td>
            <td>8.895</td>
            <td>79.127</td>
            <td>-</td>
        </tr>
        <tr>
            <td>SO2</td>
            <td>Numerical</td>
            <td>0</td>
            <td>-6.2</td>
            <td>8</td>
            <td>44.9</td>
            <td>10.015</td>
            <td>6.750</td>
            <td>45.567</td>
            <td>-</td>
        </tr>
        <tr>
            <td>CO</td>
            <td>Numerical</td>
            <td>0</td>
            <td>0.65</td>
            <td>1.41</td>
            <td>3.72</td>
            <td>1.500</td>
            <td>0.546</td>
            <td>0.298</td>
            <td>-</td>
        </tr>
        <tr>
            <td>Proximity_to_Industrial_Areas</td>
            <td>Numerical</td>
            <td>0</td>
            <td>2.5</td>
            <td>7.9</td>
            <td>25.8</td>
            <td>8.425</td>
            <td>3.611</td>
            <td>13.039</td>
            <td>-</td>
        </tr>
        <tr>
            <td>Population_Density</td>
            <td>Numerical</td>
            <td>0</td>
            <td>188</td>
            <td>494</td>
            <td>957</td>
            <td>497.424</td>
            <td>152.754</td>
            <td>23333.810</td>
            <td>-</td>
        </tr>
        <tr>
            <td>Air_Quality</td>
            <td>Categorical</td>
            <td>0</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>4</td>
        </tr>
    </tbody>
</table>
    <h2>3. Preprocessing</h2>

<h3>3.1 Drop Features</h3>
<p>
    Our R Shiny application allows users to drop irrelevant features from the dataset. However, in this dataset, all features seem to be highly relevant to the target variable. There are no additional features like IDs or other variables that could create issues during analysis. As such, we decided not to drop any features.
</p>

<h3>3.2 Convert Numerical to Categorical or Categorical to Numerical</h3>
<p>
    All features in this dataset are appropriately classified from the beginning. Our R Shiny application enables users to convert numerical features into categorical features and vice versa. Users can restore features to their original state, ensuring consistency in our implementation. However, categorical features without numerical representation cannot be converted into numerical features. In this case, no conversions were necessary as the dataset was already well-structured.
</p>

<h3>3.3 Handle Missing Values</h3>
<p>
This dataset does not contain any missing values, as shown in the table above. Nevertheless, our R Shiny application provides several methods for handling missing values, including suppression, replacing missing values with the median, mode, or mean, depending on the users preference.
</p>
       
<h3>3.4 Handling Outliers</h3>
<p>
Our application also offers robust methods to handle outliers. However, based on our analysis, this dataset does not contain any significant outliers.
</p>
       
<h3>3.5 Data Transformation</h3>
<p>
Our R Shiny application provides various data transformation techniques, including standardization and normalization using Min-Max Scaling, Z-score normalization, and log transformation. In this dataset, we applied Min-Max Scaling to the <b>Temperature</b> and <b>Humidity</b> features. For <b>PM2.5</b>, <b>PM10</b>, <b>NO2</b>, <b>SO2</b>, <b>CO</b>, <b>Proximity to Industrial Areas</b>, and <b>Population Density</b>, we applied log transformation to ensure proper scaling and feature distribution.
</p>
       
<h3>3.6 Encoding Data</h3>
<p>
Our application supports both label encoding and one-hot encoding (dummy variables). In this dataset, we have one categorical variable, <b>Air Quality</b>, which we selected as the target variable. We applied label encoding to this variable to ensure correct training for machine learning models. Our interface recommends that the target variable should use one-hot encoding to maximize compatibility during training.
</p>
       
<h3>3.7 Submitting and Save</h3>
<p>
Once preprocessing is complete, users can submit the transformed dataset. Please note that no further preprocessing can be done after submission. Below is the link to download the preprocessed dataset:
</p>
<p>
<a href="https://drive.google.com/uc?export=download&id=1sohBJ7PJJYyEdDYaqUEE3j_rx9koR3_x" target="_blank">Download Preprocessed Dataset</a>
</p>

    <h2>4. EDA (Exploratory Data Analysis)</h2>

<h3>4.1 Unidimensional Analysis</h3>

<h4>4.1.1 Histogram</h4>
<p>Below are histograms for each feature, providing a visual overview of their distributions.</p>
<ul>
    <li>
        <h5>Feature 1: Temperature</h5>
        <img src="https://i.ibb.co/CJ8TxYM/Histo-Feature1.png" alt="Histogram for Temperature" width="600">
    </li>
    <li>
        <h5>Feature 2: Humidity</h5>
        <img src="https://i.ibb.co/qykVQJj/Histo-Feature2.png" alt="Histogram for Humidity" width="600">
    </li>
    <li>
        <h5>Feature 3: PM2.5</h5>
        <img src="https://i.ibb.co/rbyMvs8/Histo-Feature3.png" alt="Histogram for PM2.5" width="600">
    </li>
    <li>
        <h5>Feature 4: PM10</h5>
        <img src="https://i.ibb.co/yqn182L/Histo-Feature4.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 5: NO2</h5>
        <img src="https://i.ibb.co/Lx2bd4v/Histo-Feature5.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 6: SO2</h5>
        <img src="https://i.ibb.co/HKcPZps/Histo-Feature6.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 7: CO</h5>
        <img src="https://i.ibb.co/KFydxrY/Histo-Feature7.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 8: Proximity to Industrial Areas</h5>
        <img src="https://i.ibb.co/ngbQqTk/Histo-Feature8.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 9: Population Density</h5>
        <img src="LINK_TO_HISTOGRAM_IMAGE_PM10" alt="Histogram for PM10" width="600">
    </li>
</ul>

<h4>4.1.2 Box Plot</h4>
<p>Box plots for each feature help identify the spread and potential outliers.</p>
<ul>

    <li>
        <h5>Feature 1: Temperature</h5>
        <img src="https://i.ibb.co/61Dx91G/boxplot-Feature1.png" alt="Box Plot for Temperature" width="600">
    </li>
    <li>
        <h5>Feature 2: Humidity</h5>
        <img src="https://i.ibb.co/pK8YqGC/boxplot-Feature2.png" alt="Box Plot for Humidity" width="600">
    </li>
    <li>
        <h5>Feature 3: PM2.5</h5>
        <img src="https://i.ibb.co/n7ZTyfC/boxplot-Feature3.png" alt="Box Plot for PM2.5" width="600">
    </li>
    <li>
        <h5>Feature 4: PM10</h5>
        <img src="https://i.ibb.co/3pxWwTH/boxplot-Feature4.png" alt="Box Plot for PM10" width="600">
    </li>
            <li>
        <h5>Feature 5: NO2</h5>
        <img src="https://i.ibb.co/KLhsxzz/boxplot-Feature5.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 6: SO2</h5>
        <img src="https://i.ibb.co/JjyBzNM/boxplot-Feature6.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 7: CO</h5>
        <img src="https://i.ibb.co/7QcdHV3/boxplot-Feature7.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 8: Proximity to Industrial Areas</h5>
        <img src="https://i.ibb.co/VtZWFCK/boxplot-Feature8.png" alt="Histogram for PM10" width="600">
    </li>
    <li>
        <h5>Feature 9: Population Density</h5>
        <img src="https://i.ibb.co/GvnbtTX/boxplot-Feature9.png" alt="Histogram for PM10" width="600">
    </li>
</ul>

<h4>4.1.3 Pie Chart</h4>
<p>The pie chart below represents the distribution of the target variable (Air Quality).</p>
<img src="https://i.ibb.co/6vCMX5f/pie-chart.png" alt="Pie Chart for Target Variable" width="600">

<h3>4.2 Bidimensional Analysis</h3>

<h4>4.2.1 Correlation Matrix</h4>
<p>The correlation matrix shows relationships between numerical features in the dataset.</p>
<img src="https://i.ibb.co/25c9972/correlation-Matrix.png" alt="Correlation Matrix" width="600">

<h4>Additional Depth Analysis</h4>
<p>
While we have included a summary of the datasets relationships, users can conduct further bidimensional analysis using our R Shiny interface. 
The interface supports tools like:
</p>
<ul>
  <li>Correlation plots</li>
  <li>Parallel box plots</li>
  <li>Bar plots</li>
  <li>Contingency tables</li>
</ul>
<p>
  We recommend using the interface for deeper insights tailored to your needs.
</p>

   <h2>5. Training and Evaluation</h2>

<h3>5.1 Selecting the Target Variable</h3>
<p>
    As mentioned above, our target variable for this dataset is <strong>Air Quality</strong>. When we select the target variable, we can visualize its distribution again, as seen in the EDA section through the pie chart or histograms. 
    <br>
    Upon analysis, the dataset shows an <strong>imbalanced distribution</strong>, where "Good Weather" is the most frequent category. However, we decided not to apply any resampling techniques. This is because:
</p>
<ul>
    <li>All four unique values of the target variable have a sufficient number of instances.</li>
    <li>The distribution makes sense since "Good Weather" is expected to occur most frequently.</li>
    <li>We believe that the imbalance will not significantly affect our training results and can be addressed later in the results if needed.</li>
</ul>

<h3>5.2 Splitting Data</h3>
<p>
    To train our models, we split the dataset into two subsets:
</p>
<ul>
    <li><strong>Training Set:</strong> 80% of the data.</li>
    <li><strong>Testing Set:</strong> 20% of the data.</li>
</ul>
<p>
    We used a <strong>hold-out method</strong> for the split, ensuring that the testing set remains untouched during the training process.
</p>

<h3>5.3 Training and Results</h3>

<h4>5.3.1 Random Forest</h4>
<p>
    We used a Random Forest model with the following parameters:
</p>
<ul>
    <li><strong>Number of Trees:</strong> 100</li>
</ul>
<p>
    After training, the following metrics were recorded:
</p>
<ul>
    <li><strong>Accuracy:</strong> 0.95 </li>
    <li><strong>Recall:</strong> 0.92 </li>
    <li><strong>Precision:</strong> 0.93 </li>
    <li><strong>F1-Score:</strong> 0.92 </li>
</ul>
<p>Below are the visualizations for the Random Forest results:</p>
<ul>
    <li>
        <h5>Confusion Matrix</h5>
        <img src="https://i.ibb.co/92pnTWR/Confusion-Matrix.png" alt="Confusion Matrix for Random Forest" width="600">
    </li>
    <li>
        <h5>AUC-ROC Curve</h5>
        <img src="https://i.ibb.co/MBjRDSr/AUC.png" alt="AUC-ROC Curve for Random Forest" width="600">
    </li>
    <li>
        <h5>Feature Importance</h5>
        <img src="https://i.ibb.co/3MhjCL6/Feature-important.png" alt="Feature Importance for Random Forest" width="600">
        <p><strong>Analysis:</strong> The feature importance plot reveals that the most influential features for the Random Forest model are 'CO', 'Industrial Areas', and 'Temperature'. These features play a significant role in the model's predictions. On the other hand, features such as 'Population Density' and 'PM10' have relatively low importance, suggesting they contribute less to the model's decision-making process. This insight can guide future data collection and feature engineering efforts.</p>
    </li>
</ul>

<h4>5.3.2 SVM (Support Vector Machine)</h4>
<p>
    We used a Support Vector Machine (SVM) model with the following parameters:
</p>
<ul>
    <li><strong>C:</strong> 0.01</li>
    <li><strong>Kernel:</strong> Linear</li>
</ul>
<p>
    After training, the following metrics were recorded:
</p>
<ul>
    <li><strong>Accuracy:</strong> 0.95 </li>
    <li><strong>Recall:</strong> 0.92 </li>
    <li><strong>Precision:</strong> 0.93 </li>
    <li><strong>F1-Score:</strong> 0.92 </li>
</ul>
<p>Below are the visualizations for the SVM results:</p>
<ul>
    <li>
        <h5>Confusion Matrix</h5>
        <img src="https://i.ibb.co/N7K8nqy/Confusion-Matrix-2.png" alt="Confusion Matrix for SVM" width="600">
    </li>
    <li>
        <h5>AUC-ROC Curve</h5>
        <img src="https://i.ibb.co/xMhd017/AUC-2.png" alt="AUC-ROC Curve for SVM" width="600">
    </li>
</ul>